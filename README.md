# NAI-FGM
Nesterov Adam Iterative Fast Gradient Method For Adversarial Attacks

#### REQUIREMENTS

The code was tested with Python 3.6.5, Tensorflow 1.12.0, Numpy 1.15.4 and cv2 3.4.2


##### Running the code

- `python nai_fsm.py`:  generate adversarial examples using NAI-FGSM.
- `python nai_si_fgm.py`:  generate adversarial examples  using NAI-SI-FGSM.

##### Example usage

After cloning the repository you can run the giving attack code to generate adversarial examples.

- Generate adversarial examples:

```
python nai_fgsm.py
```


#### Acknowledgments

Code refer heavily to [Diversity Input Attack Method](https://github.com/cihangxie/DI-2-FGSM), [Momentum Attack Method](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks) [Variance Tuning](https://github.com/JHL-HUST/VT)





